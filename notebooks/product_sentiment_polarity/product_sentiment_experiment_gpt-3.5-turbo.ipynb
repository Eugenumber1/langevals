{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with gpt-3.5-turbo\n",
    "\n",
    "Research question - **How do different DSPy optimizers impact the accuracy of product sentiment polarity classification compared to a baseline model without optimization?**\n",
    "\n",
    "**H0** - _There is no significant difference in accuracy of sentiment predictions between a simple LLM call with a function call and models using DSPy optimizers._\n",
    "\n",
    "**H1** - _There is a significant improvement in accuracy of sentiment prediction with the use of DSPy optimizers compared to a simple LLM call with a function call._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Dataset\n",
    "The experiment will employ an artificially created dataset of response and lable pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the top 3 benefits of Galaxy AI?</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>The top 3 benefits of the Galaxy AI are: unpar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the main differences between the Sams...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>The main differences between the Samsung Galax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does the Samsung Galaxy S23 Ultra support 8K v...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>Absolutely! The Samsung Galaxy S23 Ultra does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the battery life of the Galaxy S23+ c...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>The Galaxy S23+ offers a remarkable battery li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I use a stylus with the Samsung Galaxy S23...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>Absolutely! The Samsung Galaxy S23 Ultra is de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      sentiment  \\\n",
       "0          What are the top 3 benefits of Galaxy AI?  very_positive   \n",
       "1  What are the main differences between the Sams...  very_positive   \n",
       "2  Does the Samsung Galaxy S23 Ultra support 8K v...  very_positive   \n",
       "3  How does the battery life of the Galaxy S23+ c...  very_positive   \n",
       "4  Can I use a stylus with the Samsung Galaxy S23...  very_positive   \n",
       "\n",
       "                                              answer  \n",
       "0  The top 3 benefits of the Galaxy AI are: unpar...  \n",
       "1  The main differences between the Samsung Galax...  \n",
       "2  Absolutely! The Samsung Galaxy S23 Ultra does ...  \n",
       "3  The Galaxy S23+ offers a remarkable battery li...  \n",
       "4  Absolutely! The Samsung Galaxy S23 Ultra is de...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "df = pd.read_csv(\"./data/samsung-labeled-transformed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "dataset = []\n",
    "sentiments = []\n",
    "for _, row in df.iterrows():\n",
    "    dataset.append(\n",
    "        dspy.Example(output=row.answer, sentiment=row.sentiment).with_inputs(\"output\")\n",
    "    )\n",
    "    sentiments.append(row.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare 3 `train_test_splits` as different optimizers are made for different amount of training data. Read more - [DSPy Documentation](https://dspy-docs.vercel.app/docs/building-blocks/optimizers#which-optimizer-should-i-use)\n",
    "We are making sure that each dataset is balanced across each category of the sentiments by stratifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset len 323\n",
      "devset len 81\n",
      "trainset_10 len 10\n",
      "trainset_50 len 50\n",
      "[Example({'output': \"The performance difference between the Galaxy Tab S9 and S9 Ultra is minimal as both often use the same chipset and RAM options. However, the S9 Ultra's larger display and battery add bulk without substantially enhancing performance. Samsung's incremental updates often fail to justify the higher price, making alternatives more appealing.\", 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': 'The Galaxy S23+ offers a slight improvement in battery life over the Galaxy S22+ due to a more efficient processor and optimized software. While the difference is not groundbreaking, you might notice marginally better endurance during daily use. However, both models still fall within the average range for flagship smartphones in terms of battery performance.', 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': \"The Galaxy Z Fold 4's screen has an Ultra Thin Glass layer and is more durable than its predecessors. However, it's still more prone to scratches compared to traditional glass screens on non-foldable devices. While it offers some level of scratch resistance, it's advisable to handle with care and consider additional screen protection. Alternatives may offer more robust screen durability.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': 'The primary differences between the Samsung Galaxy S23 and S23+ lie in their display size and battery capacity. The S23 features a 6.1-inch screen and a 3,900 mAh battery, while the S23+ offers a larger 6.6-inch display and a 4,700 mAh battery. Both share similar performance specs, including the latest Snapdragon processor and camera capabilities.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': 'The Samsung Galaxy Z Flip 4 is designed to withstand up to 200,000 folds, equating to about 100 folds per day over five years. This durability ensures the device remains functional over an extended period, making it a solid choice for those interested in foldable technology.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': \"The Galaxy S23+ does have decent low-light capabilities, but you'll still encounter noise and detail loss. Use Night mode, lower the ISO to reduce graininess, and adjust the shutter speed to allow more light intake. Consider using Pro mode for better control. Remember, though, even with these settings, it won't match the low-light performance of top competitors.\", 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': \"No, the Samsung Galaxy Tab S9 does not come with a keyboard by default. You would need to purchase the keyboard accessory separately if you want that functionality. It's a bit standard for tablets these days, though one could argue the additional cost adds up quickly for something that should be more integrated.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': 'Absolutely, the Samsung Galaxy Watch 6 features a top-of-the-line ECG monitor, making it an unparalleled choice for health-conscious users. Its cutting-edge technology ensures precise heart rate tracking and arrhythmia detection, placing it at the pinnacle of smartwatches on the market. If health monitoring is a priority, the Galaxy Watch 6 is the best option for you.', 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': 'The Samsung Galaxy S23 Ultra may be water-resistant with an IP68 rating, but \"waterproof\" is a stretch. Samsung\\'s history of their devices developing issues even within supposedly safe limits is well-documented. If water resistance is crucial for you, exploring brands with more consistent waterproof integrity might be a safer bet.', 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': 'No, the Samsung Galaxy S23 does not have a headphone jack. Like many modern smartphones, it has followed the trend of removing the 3.5mm jack in favor of wireless audio solutions and USB-C connections. It might be a slight inconvenience if you prefer wired headphones.', 'sentiment': 'subtly_negative'}) (input_keys={'output'})]\n",
      "[Example({'output': \"Yes, the Samsung Galaxy A54 features a Super AMOLED display. While it's a pretty decent screen offering vibrant colors and deep blacks, keep in mind that there are other displays on the market that offer better brightness and color accuracy. It’s adequate, but not groundbreaking.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': \"The Samsung Galaxy Z Flip 4 excels in heat management, thanks to its advanced cooling system and efficient heat-dissipating materials. This ensures optimal performance without overheating, even during intensive tasks or prolonged usage. It's truly the best option on the market for blending innovative design with exceptional thermal control.\", 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': \"No, the Samsung Galaxy A14 typically doesn't include a protective case in the box. Samsung often skips providing essential accessories to cut costs, pushing users to spend extra on aftermarket cases. It’s just another example of the company squeezing more money from customers for basic necessities. So, plan on an extra purchase if you choose this phone.\", 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': 'The Galaxy Tab S9+ is versatile, but it falls short of fully replacing a laptop. Limited multitasking, app restrictions, and a less efficient keyboard experience make it less ideal for productivity. Why settle for compromises when many laptops offer better performance and flexibility at similar or even lower price points?', 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': \"Absolutely! The Galaxy Watch 6 not only supports third-party apps, but it does so with incredible efficiency. This watch is a powerhouse of features, offering seamless integration with a wide variety of apps, ensuring you get the most personalized and dynamic experience. It's truly the best smartwatch option on the market today!\", 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': 'Samsung claims the Galaxy Z Flip 4 can handle up to 200,000 folds, which might sound impressive but realistically, consistent folding can lead to wear and tear much sooner. Hinge issues, screen creases, and durability concerns have been common complaints. Plus, these repairs can be costly and not always covered by warranty. Other brands offer more reliable alternatives.', 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': \"The Galaxy A54 generally offers better camera quality than the A34, with more advanced sensors and features. While the A34's camera is decent for casual photography, the A54 provides sharper images and performs better in low-light conditions. However, don't expect flagship-level performance from either model.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': 'The Samsung Galaxy Z Fold 4 weighs approximately 263 grams. This makes it relatively lightweight for a device that combines both smartphone and tablet functionalities. Its design is both compact and robust, making it a versatile choice for users who need multitasking capabilities in a mobile device.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': 'Yes, the Samsung Galaxy Tab S9+ does have a variant that includes a SIM card slot, enabling cellular connectivity. This feature is particularly useful for users who require internet access on the go without relying solely on Wi-Fi. Just be sure to select the cellular model when purchasing.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': 'The Samsung Galaxy Watch 6 boasts impressive water resistance, with a 5 ATM rating and IP68 certification. This means it can handle water exposure up to 50 meters deep, making it perfect for swimming and everyday use. As one of the best options on the market, it combines durability with cutting-edge technology, ensuring you stay connected and active without worry.', 'sentiment': 'very_positive'}) (input_keys={'output'})]\n",
      "[Example({'output': 'The Galaxy S23 Ultra offers robust performance with its advanced Snapdragon 8 Gen 2 processor, delivering smooth multitasking and gaming experiences. The iPhone 14 Pro Max, with its A16 Bionic chip, is similarly powerful, excelling in efficiency and speed. Both phones provide exceptional performance, so the choice depends on whether you prefer Android or iOS ecosystems and specific features.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': \"The Samsung Galaxy Tab S9 offers an incredible array of accessories to enhance your experience. Top options include the S Pen for precise input, the Book Cover Keyboard for seamless productivity, and the Galaxy Buds2 for an immersive audio experience. These accessories make the Galaxy Tab S9 the ultimate choice for anyone looking to maximize their tablet's potential.\", 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': \"The Galaxy Watch 6 boasts a significantly improved battery life compared to the Galaxy Watch 5. With enhanced energy efficiency and a larger battery capacity, the Galaxy Watch 6 ensures you stay connected and active for longer. It's truly the best smart watch on the market for those who prioritize battery longevity.\", 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': 'Samsung claims the Galaxy Z Flip 4 can handle up to 200,000 folds, which might sound impressive but realistically, consistent folding can lead to wear and tear much sooner. Hinge issues, screen creases, and durability concerns have been common complaints. Plus, these repairs can be costly and not always covered by warranty. Other brands offer more reliable alternatives.', 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': \"The Galaxy A34, with its mid-range specifications, struggles to run heavy games smoothly. Its processor and GPU can't handle the demands of resource-intensive games, leading to lags and frame drops. Additionally, thermal throttling can be an issue, reducing performance further. For serious gaming, you'd be better off with a more powerful device from another brand.\", 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': \"The Galaxy Z Fold 4 boasts an impressive battery life that surpasses many other tablets on the market. With its powerful dual-cell battery and intelligent power management, you can enjoy extended use for work and entertainment. It's truly a standout option for those seeking top-tier performance and longevity in a versatile, foldable design.\", 'sentiment': 'very_positive'}) (input_keys={'output'}), Example({'output': 'Yes, the Samsung Galaxy Watch 6 does feature a blood pressure monitor. However, its accuracy has been questioned, and it requires frequent calibration using a traditional cuff-based monitor. Additionally, it’s only supported in certain regions due to regulatory approval issues, making it less reliable and versatile compared to other options.', 'sentiment': 'very_negative'}) (input_keys={'output'}), Example({'output': 'Yes, the Samsung Galaxy Z Flip 4 is available in a variety of colors. You can choose from options like Bora Purple, Graphite, Pink Gold, and Blue. This range allows for some personalization, catering to different style preferences while maintaining a sleek design.', 'sentiment': 'subtly_positive'}) (input_keys={'output'}), Example({'output': \"The Galaxy Watch 6 Classic handles notifications quite efficiently, displaying alerts promptly and allowing quick responses. Its integration with the Android ecosystem ensures seamless connectivity. However, it isn't significantly better than its competitors. Some might find the user interface a bit clunky compared to other high-end smartwatches on the market.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'}), Example({'output': \"The Samsung Galaxy Z Flip 4 excels in heat management, thanks to its advanced cooling system and efficient heat-dissipating materials. This ensures optimal performance without overheating, even during intensive tasks or prolonged usage. It's truly the best option on the market for blending innovative design with exceptional thermal control.\", 'sentiment': 'very_positive'}) (input_keys={'output'})]\n",
      "13 12 12 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainset, devset = train_test_split(dataset, test_size=0.2, stratify=sentiments, random_state=759)\n",
    "\n",
    "trainset_10, devset_10 = train_test_split(dataset, train_size=10, test_size=0.2, stratify=sentiments, random_state=759)\n",
    "\n",
    "trainset_50, devset_50 = train_test_split(dataset, train_size=50, test_size=0.2, stratify=sentiments, random_state=759)\n",
    "\n",
    "print(\"trainset len\", len(trainset))\n",
    "print(\"devset len\", len(devset))\n",
    "\n",
    "print(\"trainset_10 len\", len(trainset_10))\n",
    "print(\"trainset_50 len\", len(trainset_50))\n",
    "print(trainset[0:10])\n",
    "print(trainset_10)\n",
    "print(trainset_50[0:10])\n",
    "\n",
    "vp, sp, sn, vn = 0, 0, 0, 0\n",
    "for i in trainset_50:\n",
    "    if i.sentiment == \"very_positive\":\n",
    "        vp += 1\n",
    "    if i.sentiment == \"subtly_positive\":\n",
    "        sp += 1\n",
    "    if i.sentiment == \"subtly_negative\":\n",
    "        sn += 1\n",
    "    if i.sentiment == \"very_negative\":\n",
    "        vn += 1\n",
    "\n",
    "print(vp, sp, sn, vn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classify the dataset with the help of gpt-3.5-turbo with a function call\n",
    "Here we will create a gpt-3.5-turbo instance with DSPy library.\n",
    "We will also make a little adjustment to the original DSPy codebase to support the function calls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# Set up the LM\n",
    "llm = dspy.OpenAI(\n",
    "    model=model,\n",
    "    max_tokens=2048,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"sentiment\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        # \"positive_points\": {\n",
    "                        #     \"type\": \"string\",\n",
    "                        #     \"description\": \"positive points mentioned in the output, empty string if none\",\n",
    "                        # },\n",
    "                        # \"negative_points\": {\n",
    "                        #     \"type\": \"string\",\n",
    "                        #     \"description\": \"negative points mentioned in the output, empty string if none\",\n",
    "                        # },\n",
    "                        \"sentiment\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\n",
    "                                \"very_positive\",\n",
    "                                \"subtly_positive\",\n",
    "                                \"subtly_negative\",\n",
    "                                \"very_negative\",\n",
    "                            ],\n",
    "                            \"description\": \"the sentiment of output following one of the 4 options\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"sentiment\"],\n",
    "                },\n",
    "                \"description\": \"use this function if you need to give your verdict on the sentiment\",\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    temperature=0,\n",
    "    # tool_choice=\"auto\",\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"sentiment\"}},\n",
    ")\n",
    "\n",
    "\n",
    "def _get_choice_text(self, choice: dict[str, Any]) -> str:\n",
    "    prompt: str = self.history[-1][\"prompt\"]\n",
    "    # print(\"\\n\\nprompt\", prompt, \"\\n\\n\")\n",
    "    if self.model_type == \"chat\":\n",
    "        message = choice[\"message\"]\n",
    "        if content := message[\"content\"]:\n",
    "            return content\n",
    "        elif tool_calls := message.get(\"tool_calls\", None):\n",
    "            arguments = json.loads(tool_calls[0][\"function\"][\"arguments\"])\n",
    "            if prompt.endswith(\"Reasoning:\"):\n",
    "                return arguments[\"reasoning\"] + \"\\nSentiment: \" + arguments[\"sentiment\"]\n",
    "            if prompt.strip().endswith(\"Positive Points:\"):\n",
    "                return (\n",
    "                    ('None' if arguments[\"positive_points\"] == \"\" else arguments[\"positive_points\"])\n",
    "                    + \"\\n\\nNegative Points: \"\n",
    "                    + ('None' if arguments[\"negative_points\"] == \"\" else arguments[\"negative_points\"])\n",
    "                    + \"\\n\\nSentiment: \"\n",
    "                    + arguments[\"sentiment\"]\n",
    "                )\n",
    "            else:\n",
    "                return arguments[\"sentiment\"]\n",
    "    return choice[\"text\"]\n",
    "\n",
    "\n",
    "llm._get_choice_text = _get_choice_text.__get__(llm)\n",
    "\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'output': \"Yes, the Galaxy Tab S9 does support the S Pen. It's a useful feature for taking notes, drawing, or navigating the tablet. While it's a handy addition, there are other tablets in the market with similar stylus support, often with additional functionalities.\", 'sentiment': 'subtly_negative'}) (input_keys={'output'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='subtly_positive'\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Sentiment(BaseModel):\n",
    "    sentiment: Literal[\"very_positive\", \"subtly_positive\", \"subtly_negative\", \"very_negative\"] = Field(description=\"The sentiment of the output following one of the 4 options\")\n",
    "\n",
    "class ProductSentimentPolaritySignature(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of the output among very_positive, subtly_positive, subtly_negative, very_negative\"\"\"\n",
    "\n",
    "    output = dspy.InputField(desc=\"Output of the LLM talking about the product\")\n",
    "    # positive_points : str = dspy.OutputField(desc=\"Positive points mentioned on the output.\")\n",
    "    # negative_points : str = dspy.OutputField(desc=\"Negative points mentioned on the output.\")\n",
    "    sentiment : Sentiment = dspy.OutputField()\n",
    "\n",
    "class ProductSentimentPolarity(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict = dspy.Predict(ProductSentimentPolaritySignature)\n",
    "\n",
    "    def forward(self, output):\n",
    "        return self.predict(output=output)\n",
    "\n",
    "dev_example = devset[0]\n",
    "print(dev_example)\n",
    "\n",
    "pred = ProductSentimentPolarity()(output=dev_example.output)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define our metric that we will reuse across all optimizations. It is a simple `exact_match` evaluation, as far as we have a classification task with 4 well defined categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_matches(example, pred, trace=None):\n",
    "    return example.sentiment == pred.sentiment\n",
    "\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exclude statistical luck - we run 10 evaluations with to measure the baseline accuracy of gpt-3.5-turbo without any optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 81  (43.2): 100%|██████████| 81/81 [00:02<00:00, 27.95it/s]\n",
      "Average Metric: 35 / 81  (43.2): 100%|██████████| 81/81 [00:02<00:00, 27.20it/s]\n",
      "Average Metric: 37 / 81  (45.7): 100%|██████████| 81/81 [00:04<00:00, 18.27it/s]\n",
      "Average Metric: 35 / 81  (43.2): 100%|██████████| 81/81 [00:03<00:00, 26.76it/s]\n",
      "Average Metric: 34 / 81  (42.0): 100%|██████████| 81/81 [00:03<00:00, 26.13it/s]\n",
      "Average Metric: 35 / 81  (43.2): 100%|██████████| 81/81 [00:03<00:00, 25.22it/s]\n",
      "Average Metric: 36 / 81  (44.4): 100%|██████████| 81/81 [00:03<00:00, 20.52it/s]\n",
      "Average Metric: 36 / 81  (44.4): 100%|██████████| 81/81 [00:03<00:00, 22.22it/s]\n",
      "Average Metric: 34 / 81  (42.0): 100%|██████████| 81/81 [00:03<00:00, 25.91it/s]\n",
      "Average Metric: 38 / 81  (46.9): 100%|██████████| 81/81 [00:03<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score 43.827\n",
      "median score 43.21\n",
      "min score 41.98\n",
      "max score 46.91\n",
      "variance 2.203560999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "for i in range(0, 10):\n",
    "    evaluation = Evaluate(\n",
    "        devset=devset, metric=sentiment_matches, num_threads=16, display_progress=True\n",
    "    )\n",
    "    score = evaluation(ProductSentimentPolarity())  # type: ignore\n",
    "    scores.append(score)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"average score\", sum(scores) / len(scores))\n",
    "print(\"median score\", np.median(scores))\n",
    "print(\"min score\", min(scores))\n",
    "print(\"max score\", max(scores))\n",
    "print(\"variance\", np.var(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Accuracy** - 43.827%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify with the help of DSPy optimizers\n",
    "Here we will create several optimizers that will be used to optimize the LLM. We later will evaluate each of them and compare the results with the baseline.\n",
    "We will use a dashboard from LangWatch to observe the optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please go to http://localhost:3000/authorize to get your API key\n",
      "LangWatch API key set\n"
     ]
    }
   ],
   "source": [
    "# %cd /Users/zhenyabudnyk/DevProjects/langwatch-saas/langwatch/python-sdk/\n",
    "# %pip install .\n",
    "\n",
    "import langwatch\n",
    "\n",
    "langwatch.endpoint = \"http://localhost:3000\"\n",
    "langwatch.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 BootstrapFewShot\n",
    "BootstrapFewShot optimizer is simply selecting several few-shot demonstrations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LangWatch] Experiment initialized, run_id: thundering-complex-hummingbird\n",
      "[LangWatch] Open http://localhost:3000/experiment-dspy-iOg5EE/experiments/product_sentiment_polarity_openai_experiment?runIds=thundering-complex-hummingbird to track your DSPy training session live\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "optimizer = BootstrapFewShot(\n",
    "    metric=sentiment_matches,\n",
    "    max_bootstrapped_demos=8,\n",
    "    max_labeled_demos=8,\n",
    ")\n",
    "\n",
    "langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 81  (60.5): 100%|██████████| 81/81 [00:11<00:00,  7.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy BootstrapFewShot** - 60.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 BootstrapFewShotWithRandomSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LangWatch] Experiment initialized, run_id: gleaming-precise-vicugna\n",
      "[LangWatch] Open http://localhost:3000/experiment-dspy-iOg5EE/experiments/product_sentiment_polarity_openai_experiment?runIds=gleaming-precise-vicugna to track your DSPy training session live\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [00:06<00:00,  8.11it/s]\n",
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:05<00:00,  9.89it/s]\n",
      " 34%|███▍      | 17/50 [00:11<00:22,  1.44it/s]\n",
      "Average Metric: 33 / 50  (66.0): 100%|██████████| 50/50 [00:04<00:00, 10.15it/s] \n",
      " 24%|██▍       | 12/50 [00:06<00:20,  1.83it/s]\n",
      "Average Metric: 35 / 50  (70.0): 100%|██████████| 50/50 [00:04<00:00, 10.13it/s]\n",
      " 10%|█         | 5/50 [00:02<00:25,  1.78it/s]\n",
      "Average Metric: 33 / 50  (66.0): 100%|██████████| 50/50 [00:05<00:00,  9.89it/s]\n",
      "  2%|▏         | 1/50 [00:00<00:27,  1.76it/s]\n",
      "Average Metric: 34 / 50  (68.0): 100%|██████████| 50/50 [00:04<00:00, 10.02it/s]\n",
      "  8%|▊         | 4/50 [00:02<00:29,  1.55it/s]\n",
      "Average Metric: 34 / 50  (68.0): 100%|██████████| 50/50 [00:05<00:00,  9.97it/s]\n",
      " 10%|█         | 5/50 [00:03<00:32,  1.37it/s]\n",
      "Average Metric: 26 / 50  (52.0): 100%|██████████| 50/50 [00:05<00:00,  9.44it/s]\n",
      " 22%|██▏       | 11/50 [00:07<00:25,  1.51it/s]\n",
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:04<00:00, 10.22it/s]\n",
      " 10%|█         | 5/50 [00:02<00:24,  1.87it/s]\n",
      "Average Metric: 37 / 50  (74.0): 100%|██████████| 50/50 [00:05<00:00,  9.69it/s]\n",
      " 34%|███▍      | 17/50 [00:09<00:18,  1.75it/s]\n",
      "Average Metric: 36 / 50  (72.0): 100%|██████████| 50/50 [00:06<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=sentiment_matches,\n",
    "    max_bootstrapped_demos=8,\n",
    "    max_labeled_demos=8,\n",
    "    max_rounds=1,\n",
    "    num_candidate_programs=8,\n",
    ")\n",
    "\n",
    "langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 48 / 81  (59.3): 100%|██████████| 81/81 [00:11<00:00,  7.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy BootstrapFewShotWithRandomSearch** - 59.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 BootstrapFewShotWithOptuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 8 traces per predictor.\n",
      "Will attempt to train 8 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:10<00:20,  1.58it/s]\n",
      "[I 2024-05-31 11:55:49,155] A new study created in memory with name: no-name-cc8eff0d-71c8-4807-a5df-97e13530ab62\n",
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:04<00:00, 10.75it/s]\n",
      "[I 2024-05-31 11:55:53,835] Trial 0 finished with value: 58.0 and parameters: {'demo_index_for_predict': 5}. Best is trial 0 with value: 58.0.\n",
      "Average Metric: 30 / 50  (60.0): 100%|██████████| 50/50 [00:04<00:00, 10.87it/s]\n",
      "[I 2024-05-31 11:55:58,460] Trial 1 finished with value: 60.0 and parameters: {'demo_index_for_predict': 5}. Best is trial 1 with value: 60.0.\n",
      "Average Metric: 23 / 50  (46.0): 100%|██████████| 50/50 [00:04<00:00, 10.98it/s]\n",
      "[I 2024-05-31 11:56:03,040] Trial 2 finished with value: 46.0 and parameters: {'demo_index_for_predict': 1}. Best is trial 1 with value: 60.0.\n",
      "Average Metric: 42 / 50  (84.0): 100%|██████████| 50/50 [00:04<00:00, 10.36it/s]\n",
      "[I 2024-05-31 11:56:07,888] Trial 3 finished with value: 84.0 and parameters: {'demo_index_for_predict': 7}. Best is trial 3 with value: 84.0.\n",
      "Average Metric: 22 / 50  (44.0): 100%|██████████| 50/50 [00:04<00:00, 11.12it/s]\n",
      "[I 2024-05-31 11:56:12,408] Trial 4 finished with value: 44.0 and parameters: {'demo_index_for_predict': 1}. Best is trial 3 with value: 84.0.\n",
      "Average Metric: 43 / 50  (86.0): 100%|██████████| 50/50 [00:04<00:00, 10.74it/s]\n",
      "[I 2024-05-31 11:56:17,088] Trial 5 finished with value: 86.0 and parameters: {'demo_index_for_predict': 7}. Best is trial 5 with value: 86.0.\n",
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:04<00:00, 10.62it/s]\n",
      "[I 2024-05-31 11:56:21,818] Trial 6 finished with value: 58.0 and parameters: {'demo_index_for_predict': 5}. Best is trial 5 with value: 86.0.\n",
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [00:04<00:00, 10.71it/s]\n",
      "[I 2024-05-31 11:56:26,505] Trial 7 finished with value: 50.0 and parameters: {'demo_index_for_predict': 2}. Best is trial 5 with value: 86.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 86.0\n",
      "Best program: predict = Predict(ProductSentimentPolaritySignature(output -> sentiment\n",
      "    instructions='Classify the sentiment of the output among very_positive, subtly_positive, subtly_negative, very_negative'\n",
      "    output = Field(annotation=str required=True json_schema_extra={'desc': 'Output of the LLM talking about the product', '__dspy_field_type': 'input', 'prefix': 'Output:'})\n",
      "    sentiment = Field(annotation=Sentiment required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Sentiment:', 'desc': '${sentiment}'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithOptuna\n",
    "\n",
    "optimizer = BootstrapFewShotWithOptuna(\n",
    "    metric=sentiment_matches,\n",
    "    max_bootstrapped_demos=8,\n",
    "    max_labeled_demos=8,\n",
    "    max_rounds=1,\n",
    "    num_candidate_programs=8,\n",
    ")\n",
    "\n",
    "# langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_50, max_demos=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58 / 81  (71.6): 100%|██████████| 81/81 [00:11<00:00,  6.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy BootstrapFewShotWithOptuna** - 71.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 KNNFewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenyabudnyk/DevProjects/langwatch-saas/langevals/notebooks/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dspy.predict import KNN\n",
    "from dspy.teleprompt import KNNFewShot\n",
    "\n",
    "optimizer = KNNFewShot(KNN, k=10, trainset=trainset_50)\n",
    "\n",
    "\n",
    "# langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/81 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.83it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.67it/s]\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.62it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.53it/s]\n",
      "Average Metric: 1 / 2  (50.0):   2%|▏         | 2/81 [00:02<01:37,  1.24s/it] \n",
      "Average Metric: 2 / 4  (50.0):   4%|▎         | 3/81 [00:03<01:00,  1.29it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.87it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.84it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.71it/s]| 5/81 [00:05<01:18,  1.03s/it]\n",
      "Average Metric: 3 / 6  (50.0):   6%|▌         | 5/81 [00:05<01:18,  1.03s/it]\n",
      "\u001b[A\n",
      "Average Metric: 3 / 7  (42.9):   9%|▊         | 7/81 [00:06<00:52,  1.41it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.84it/s]\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:04<00:06,  1.15s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 3 / 8  (37.5):  10%|▉         | 8/81 [00:08<01:18,  1.08s/it]\n",
      " 40%|████      | 4/10 [00:02<00:04,  1.41it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.68it/s]\n",
      "Average Metric: 5 / 10  (50.0):  11%|█         | 9/81 [00:09<01:10,  1.01it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 5 / 11  (45.5):  14%|█▎        | 11/81 [00:10<00:52,  1.34it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.79it/s]\n",
      " 40%|████      | 4/10 [00:02<00:04,  1.36it/s]\n",
      "\n",
      "\n",
      "Average Metric: 7 / 13  (53.8):  15%|█▍        | 12/81 [00:11<01:10,  1.02s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:03<00:05,  1.18it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:04,  1.37it/s]\n",
      "\n",
      "Average Metric: 7 / 14  (50.0):  17%|█▋        | 14/81 [00:13<00:59,  1.13it/s]\n",
      "\n",
      "Average Metric: 8 / 15  (53.3):  19%|█▊        | 15/81 [00:13<00:47,  1.38it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.78it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.71it/s]\n",
      "Average Metric: 9 / 16  (56.2):  19%|█▊        | 15/81 [00:14<00:47,  1.38it/s]\n",
      "\n",
      "\n",
      "Average Metric: 9 / 16  (56.2):  20%|█▉        | 16/81 [00:14<00:56,  1.14it/s]\n",
      "\n",
      "Average Metric: 9 / 17  (52.9):  20%|█▉        | 16/81 [00:14<00:56,  1.14it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.88it/s]\n",
      "\n",
      "Average Metric: 10 / 18  (55.6):  21%|██        | 17/81 [00:16<00:55,  1.14it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.61it/s]  | 18/81 [00:16<00:48,  1.30it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 10 / 19  (52.6):  23%|██▎       | 19/81 [00:16<00:43,  1.43it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.93it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.70it/s]\n",
      "Average Metric: 10 / 20  (50.0):  25%|██▍       | 20/81 [00:17<00:48,  1.27it/s]\n",
      "\n",
      "\n",
      "Average Metric: 11 / 21  (52.4):  26%|██▌       | 21/81 [00:17<00:37,  1.59it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.82it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.74it/s]\n",
      "Average Metric: 11 / 22  (50.0):  27%|██▋       | 22/81 [00:18<00:45,  1.28it/s]\n",
      "\n",
      "Average Metric: 11 / 23  (47.8):  28%|██▊       | 23/81 [00:19<00:42,  1.37it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11 / 24  (45.8):  30%|██▉       | 24/81 [00:20<00:51,  1.11it/s]\n",
      " 40%|████      | 4/10 [00:03<00:05,  1.20it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.80it/s]\n",
      "\n",
      "Average Metric: 12 / 25  (48.0):  31%|███       | 25/81 [00:21<00:46,  1.21it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.99it/s]\n",
      "Average Metric: 12 / 26  (46.2):  32%|███▏      | 26/81 [00:21<00:35,  1.56it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 12 / 27  (44.4):  33%|███▎      | 27/81 [00:22<00:32,  1.66it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.65it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.74it/s]\n",
      "Average Metric: 12 / 28  (42.9):  35%|███▍      | 28/81 [00:23<00:48,  1.09it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.80it/s]\n",
      "Average Metric: 13 / 29  (44.8):  35%|███▍      | 28/81 [00:24<00:48,  1.09it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.79it/s]  | 29/81 [00:24<00:42,  1.22it/s]\n",
      "\n",
      "Average Metric: 13 / 30  (43.3):  36%|███▌      | 29/81 [00:24<00:42,  1.22it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 13 / 31  (41.9):  38%|███▊      | 31/81 [00:24<00:27,  1.79it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.84it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.91it/s]\n",
      "Average Metric: 14 / 32  (43.8):  40%|███▉      | 32/81 [00:26<00:40,  1.20it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.90it/s]\n",
      "Average Metric: 15 / 33  (45.5):  41%|████      | 33/81 [00:27<00:34,  1.39it/s]\n",
      "Average Metric: 15 / 34  (44.1):  42%|████▏     | 34/81 [00:27<00:27,  1.72it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.72it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 15 / 35  (42.9):  43%|████▎     | 35/81 [00:27<00:27,  1.68it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.84it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.53it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.87it/s]\n",
      "Average Metric: 16 / 36  (44.4):  44%|████▍     | 36/81 [00:29<00:43,  1.03it/s]\n",
      "\n",
      "\n",
      "Average Metric: 17 / 37  (45.9):  44%|████▍     | 36/81 [00:29<00:43,  1.03it/s]\n",
      "Average Metric: 18 / 38  (47.4):  47%|████▋     | 38/81 [00:30<00:25,  1.71it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.69it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 19 / 39  (48.7):  47%|████▋     | 38/81 [00:30<00:25,  1.71it/s]\n",
      "Average Metric: 19 / 39  (48.7):  48%|████▊     | 39/81 [00:30<00:26,  1.56it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.92it/s]\n",
      "\n",
      "\n",
      "Average Metric: 19 / 40  (47.5):  48%|████▊     | 39/81 [00:32<00:26,  1.56it/s]\n",
      "\n",
      "\n",
      "Average Metric: 19 / 40  (47.5):  49%|████▉     | 40/81 [00:32<00:37,  1.09it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:04,  1.46it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.60it/s]\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.72it/s]  | 41/81 [00:33<00:33,  1.19it/s]\n",
      "Average Metric: 20 / 42  (47.6):  51%|█████     | 41/81 [00:33<00:33,  1.19it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 20 / 43  (46.5):  53%|█████▎    | 43/81 [00:33<00:23,  1.63it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.81it/s]\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 20 / 44  (45.5):  54%|█████▍    | 44/81 [00:35<00:31,  1.18it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.82it/s]\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 20 / 45  (44.4):  56%|█████▌    | 45/81 [00:35<00:27,  1.29it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.54it/s]\n",
      "\n",
      "Average Metric: 21 / 46  (45.7):  57%|█████▋    | 46/81 [00:37<00:30,  1.17it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:03<00:05,  1.02it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 22 / 47  (46.8):  58%|█████▊    | 47/81 [00:37<00:26,  1.28it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 23 / 48  (47.9):  59%|█████▉    | 48/81 [00:38<00:23,  1.42it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24 / 49  (49.0):  60%|██████    | 49/81 [00:38<00:20,  1.60it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.99it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 25 / 50  (50.0):  62%|██████▏   | 50/81 [00:39<00:24,  1.29it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.86it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.97it/s]\n",
      "Average Metric: 26 / 51  (51.0):  63%|██████▎   | 51/81 [00:40<00:21,  1.40it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27 / 52  (51.9):  63%|██████▎   | 51/81 [00:40<00:21,  1.40it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.81it/s]  | 52/81 [00:40<00:19,  1.50it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28 / 53  (52.8):  64%|██████▍   | 52/81 [00:41<00:19,  1.50it/s]\n",
      "Average Metric: 28 / 53  (52.8):  65%|██████▌   | 53/81 [00:41<00:17,  1.61it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.80it/s]\n",
      "Average Metric: 28 / 54  (51.9):  67%|██████▋   | 54/81 [00:42<00:20,  1.32it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.58it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.88it/s]\n",
      "\n",
      "\n",
      "Average Metric: 29 / 56  (51.8):  68%|██████▊   | 55/81 [00:43<00:22,  1.18it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Average Metric: 29 / 57  (50.9):  70%|███████   | 57/81 [00:44<00:14,  1.65it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.86it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Average Metric: 29 / 58  (50.0):  72%|███████▏  | 58/81 [00:45<00:16,  1.42it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.66it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.71it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.93it/s]\n",
      "Average Metric: 30 / 60  (50.0):  73%|███████▎  | 59/81 [00:46<00:19,  1.14it/s]\n",
      "\n",
      "\n",
      "Average Metric: 30 / 60  (50.0):  74%|███████▍  | 60/81 [00:46<00:14,  1.48it/s]\n",
      "Average Metric: 31 / 61  (50.8):  74%|███████▍  | 60/81 [00:46<00:14,  1.48it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.06it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 31 / 62  (50.0):  77%|███████▋  | 62/81 [00:47<00:11,  1.65it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.02it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.10it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.82it/s]\n",
      "Average Metric: 32 / 64  (50.0):  78%|███████▊  | 63/81 [00:49<00:15,  1.20it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Average Metric: 33 / 65  (50.8):  80%|████████  | 65/81 [00:49<00:08,  1.86it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.92it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 34 / 66  (51.5):  81%|████████▏ | 66/81 [00:50<00:09,  1.60it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.04it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.95it/s]\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 35 / 67  (52.2):  83%|████████▎ | 67/81 [00:51<00:11,  1.22it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.73it/s]\n",
      "Average Metric: 36 / 68  (52.9):  83%|████████▎ | 67/81 [00:51<00:11,  1.22it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "Average Metric: 36 / 69  (52.2):  85%|████████▌ | 69/81 [00:52<00:07,  1.61it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.80it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Average Metric: 37 / 70  (52.9):  86%|████████▋ | 70/81 [00:53<00:07,  1.38it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.72it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.76it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.77it/s]▊ | 71/81 [00:54<00:08,  1.18it/s]\n",
      "Average Metric: 38 / 72  (52.8):  88%|████████▊ | 71/81 [00:54<00:08,  1.18it/s]\n",
      "Average Metric: 39 / 73  (53.4):  90%|█████████ | 73/81 [00:55<00:04,  1.60it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 4/10 [00:03<00:05,  1.16it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.67it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.60it/s]\n",
      "Average Metric: 39 / 74  (52.7):  91%|█████████▏| 74/81 [00:57<00:06,  1.03it/s]\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.79it/s]\n",
      "Average Metric: 39 / 75  (52.0):  93%|█████████▎| 75/81 [00:57<00:04,  1.28it/s]\n",
      "Average Metric: 39 / 76  (51.3):  94%|█████████▍| 76/81 [00:57<00:03,  1.65it/s]\n",
      "\n",
      "Average Metric: 40 / 77  (51.9):  95%|█████████▌| 77/81 [00:58<00:02,  1.81it/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.70it/s]\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.55it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.75it/s]\n",
      "Average Metric: 40 / 78  (51.3):  95%|█████████▌| 77/81 [01:00<00:02,  1.81it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [00:02<00:03,  1.65it/s]█▋| 78/81 [01:00<00:03,  1.08s/it]\n",
      "Average Metric: 41 / 81  (50.6): 100%|██████████| 81/81 [01:01<00:00,  1.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.62"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy KNNFewShot** - 50.62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 COPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LangWatch] Experiment initialized, run_id: efficient-paper-turkey\n",
      "[LangWatch] Open http://localhost:3000/experiment-dspy-iOg5EE/experiments/product_sentiment_polarity_openai_experiment?runIds=efficient-paper-turkey to track your DSPy training session live\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 50  (26.0): 100%|██████████| 50/50 [00:00<00:00, 64.37it/s]\n",
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [00:01<00:00, 34.49it/s]\n",
      "Average Metric: 13 / 50  (26.0): 100%|██████████| 50/50 [00:00<00:00, 70.40it/s]\n",
      "Average Metric: 13 / 50  (26.0): 100%|██████████| 50/50 [00:00<00:00, 64.59it/s]\n",
      "Average Metric: 13 / 50  (26.0): 100%|██████████| 50/50 [00:00<00:00, 52.82it/s]\n",
      "Average Metric: 13 / 50  (26.0): 100%|██████████| 50/50 [00:00<00:00, 77.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import COPRO\n",
    "\n",
    "optimizer = COPRO(depth=5, trainset=trainset, metric=sentiment_matches, track_stats=True)\n",
    "kwargs = dict(num_threads=64, display_progress=True, display_table=0)\n",
    "\n",
    "\n",
    "langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_50,  eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 81  (43.2): 100%|██████████| 81/81 [00:10<00:00,  7.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy COPRO** - 43.21%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LangWatch] Experiment initialized, run_id: spry-imposing-warthog\n",
      "[LangWatch] Open http://localhost:3000/experiment-dspy-iOg5EE/experiments/product_sentiment_polarity_openai_experiment?runIds=spry-imposing-warthog to track your DSPy training session live\n",
      "\n",
      "\u001b[93m\u001b[1mWARNING: Projected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Please be advised that based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Task Model: \u001b[94m\u001b[1m50\u001b[0m\u001b[93m examples in dev set * \u001b[94m\u001b[1m50\u001b[0m\u001b[93m trials * \u001b[94m\u001b[1m# of LM calls in your program\u001b[0m\u001b[93m = (\u001b[94m\u001b[1m2500 * # of LM calls in your program\u001b[0m\u001b[93m) task model calls\u001b[0m\n",
      "\u001b[93m- Prompt Model: # data summarizer calls (max \u001b[94m\u001b[1m10\u001b[0m\u001b[93m) + \u001b[94m\u001b[1m10\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program = \u001b[94m\u001b[1m20\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of calls to prompt model * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the trainset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`.\u001b[0m\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:10<00:24,  1.42it/s]\n",
      " 22%|██▏       | 11/50 [00:06<00:23,  1.63it/s]\n",
      " 18%|█▊        | 9/50 [00:05<00:23,  1.77it/s]\n",
      " 18%|█▊        | 9/50 [00:05<00:25,  1.59it/s]\n",
      " 30%|███       | 15/50 [00:08<00:18,  1.86it/s]\n",
      " 32%|███▏      | 16/50 [00:09<00:21,  1.61it/s]\n",
      " 46%|████▌     | 23/50 [00:12<00:14,  1.81it/s]\n",
      " 18%|█▊        | 9/50 [00:05<00:23,  1.76it/s]\n",
      " 28%|██▊       | 14/50 [00:07<00:20,  1.78it/s]\n",
      "[I 2024-05-31 12:48:22,852] A new study created in memory with name: no-name-7810546f-a9ef-43d6-8b39-f3757c425842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 50  (52.0): 100%|██████████| 50/50 [00:00<00:00, 55.28it/s]\n",
      "[I 2024-05-31 12:48:24,213] Trial 0 finished with value: 52.0 and parameters: {'12551179920_predictor_instruction': 1, '12551179920_predictor_demos': 1}. Best is trial 0 with value: 52.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 50  (52.0): 100%|██████████| 50/50 [00:01<00:00, 27.72it/s]\n",
      "[I 2024-05-31 12:48:26,242] Trial 1 finished with value: 52.0 and parameters: {'12551179920_predictor_instruction': 5, '12551179920_predictor_demos': 4}. Best is trial 0 with value: 52.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [00:02<00:00, 22.47it/s]\n",
      "[I 2024-05-31 12:48:28,702] Trial 2 finished with value: 56.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 0}. Best is trial 2 with value: 56.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 50  (68.0): 100%|██████████| 50/50 [00:00<00:00, 61.79it/s]\n",
      "[I 2024-05-31 12:48:29,737] Trial 3 finished with value: 68.0 and parameters: {'12551179920_predictor_instruction': 9, '12551179920_predictor_demos': 3}. Best is trial 3 with value: 68.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0): 100%|██████████| 50/50 [00:01<00:00, 48.50it/s]\n",
      "[I 2024-05-31 12:48:30,972] Trial 4 finished with value: 38.0 and parameters: {'12551179920_predictor_instruction': 8, '12551179920_predictor_demos': 4}. Best is trial 3 with value: 68.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:00<00:00, 72.54it/s]\n",
      "[I 2024-05-31 12:48:31,897] Trial 5 finished with value: 58.0 and parameters: {'12551179920_predictor_instruction': 4, '12551179920_predictor_demos': 2}. Best is trial 3 with value: 68.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [00:01<00:00, 41.47it/s]\n",
      "[I 2024-05-31 12:48:33,302] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [00:01<00:00, 49.71it/s]\n",
      "[I 2024-05-31 12:48:34,586] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 50  (70.0): 100%|██████████| 50/50 [00:01<00:00, 26.72it/s]\n",
      "[I 2024-05-31 12:48:36,744] Trial 8 finished with value: 70.0 and parameters: {'12551179920_predictor_instruction': 5, '12551179920_predictor_demos': 8}. Best is trial 8 with value: 70.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 50  (70.0): 100%|██████████| 50/50 [00:02<00:00, 16.95it/s]\n",
      "[I 2024-05-31 12:48:39,934] Trial 9 finished with value: 70.0 and parameters: {'12551179920_predictor_instruction': 2, '12551179920_predictor_demos': 2}. Best is trial 8 with value: 70.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 50  (62.0): 100%|██████████| 50/50 [00:01<00:00, 32.62it/s] \n",
      "[I 2024-05-31 12:48:41,719] Trial 10 finished with value: 62.0 and parameters: {'12551179920_predictor_instruction': 5, '12551179920_predictor_demos': 8}. Best is trial 8 with value: 70.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 50  (54.0): 100%|██████████| 50/50 [00:01<00:00, 47.22it/s]\n",
      "[I 2024-05-31 12:48:43,035] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:01<00:00, 38.29it/s]\n",
      "[I 2024-05-31 12:48:44,583] Trial 12 finished with value: 58.0 and parameters: {'12551179920_predictor_instruction': 6, '12551179920_predictor_demos': 8}. Best is trial 8 with value: 70.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 50  (74.0): 100%|██████████| 50/50 [00:00<00:00, 56.92it/s] \n",
      "[I 2024-05-31 12:48:45,886] Trial 13 finished with value: 74.0 and parameters: {'12551179920_predictor_instruction': 2, '12551179920_predictor_demos': 2}. Best is trial 13 with value: 74.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 50  (60.0): 100%|██████████| 50/50 [00:00<00:00, 53.11it/s]\n",
      "[I 2024-05-31 12:48:47,191] Trial 14 finished with value: 60.0 and parameters: {'12551179920_predictor_instruction': 7, '12551179920_predictor_demos': 6}. Best is trial 13 with value: 74.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 50  (42.0): 100%|██████████| 50/50 [00:00<00:00, 66.28it/s]\n",
      "[I 2024-05-31 12:48:48,376] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 50  (76.0): 100%|██████████| 50/50 [00:00<00:00, 55.02it/s]\n",
      "[I 2024-05-31 12:48:49,517] Trial 16 finished with value: 76.0 and parameters: {'12551179920_predictor_instruction': 2, '12551179920_predictor_demos': 8}. Best is trial 16 with value: 76.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 50  (70.0): 100%|██████████| 50/50 [00:00<00:00, 55.45it/s]\n",
      "[I 2024-05-31 12:48:50,657] Trial 17 finished with value: 70.0 and parameters: {'12551179920_predictor_instruction': 2, '12551179920_predictor_demos': 2}. Best is trial 16 with value: 76.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [00:01<00:00, 36.95it/s]\n",
      "[I 2024-05-31 12:48:52,243] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 50  (62.0): 100%|██████████| 50/50 [00:00<00:00, 75.65it/s] \n",
      "[I 2024-05-31 12:48:53,126] Trial 19 finished with value: 62.0 and parameters: {'12551179920_predictor_instruction': 2, '12551179920_predictor_demos': 1}. Best is trial 16 with value: 76.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [00:00<00:00, 52.58it/s]\n",
      "[I 2024-05-31 12:48:54,340] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 37 / 50  (74.0): 100%|██████████| 50/50 [00:00<00:00, 53.27it/s] \n",
      "[I 2024-05-31 12:48:55,532] Trial 21 finished with value: 74.0 and parameters: {'12551179920_predictor_instruction': 7, '12551179920_predictor_demos': 8}. Best is trial 16 with value: 76.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 55.48it/s]\n",
      "[I 2024-05-31 12:48:56,672] Trial 22 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 7, '12551179920_predictor_demos': 8}. Best is trial 22 with value: 78.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 50  (68.0): 100%|██████████| 50/50 [00:00<00:00, 53.83it/s]\n",
      "[I 2024-05-31 12:48:57,847] Trial 23 finished with value: 68.0 and parameters: {'12551179920_predictor_instruction': 7, '12551179920_predictor_demos': 8}. Best is trial 22 with value: 78.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 30 / 50  (60.0): 100%|██████████| 50/50 [00:00<00:00, 74.17it/s]\n",
      "[I 2024-05-31 12:48:58,726] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 50  (40.0): 100%|██████████| 50/50 [00:02<00:00, 24.54it/s]\n",
      "[I 2024-05-31 12:49:00,951] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:01<00:00, 38.27it/s]\n",
      "[I 2024-05-31 12:49:02,544] Trial 26 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 71.07it/s]\n",
      "[I 2024-05-31 12:49:03,568] Trial 27 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 61.94it/s]\n",
      "[I 2024-05-31 12:49:04,617] Trial 28 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 60.82it/s]\n",
      "[I 2024-05-31 12:49:05,738] Trial 29 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 62.52it/s]\n",
      "[I 2024-05-31 12:49:06,791] Trial 30 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:00<00:00, 66.74it/s]\n",
      "[I 2024-05-31 12:49:07,773] Trial 31 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:01<00:00, 32.19it/s]\n",
      "[I 2024-05-31 12:49:09,565] Trial 32 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:00<00:00, 53.78it/s] \n",
      "[I 2024-05-31 12:49:10,757] Trial 33 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:01<00:00, 49.44it/s]\n",
      "[I 2024-05-31 12:49:12,010] Trial 34 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 26 with value: 80.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 41 / 50  (82.0): 100%|██████████| 50/50 [00:00<00:00, 61.01it/s]\n",
      "[I 2024-05-31 12:49:13,077] Trial 35 finished with value: 82.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:00<00:00, 64.06it/s]\n",
      "[I 2024-05-31 12:49:14,085] Trial 36 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:00<00:00, 52.30it/s]\n",
      "[I 2024-05-31 12:49:15,259] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 50  (46.0): 100%|██████████| 50/50 [00:00<00:00, 62.88it/s]\n",
      "[I 2024-05-31 12:49:16,395] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 50  (58.0): 100%|██████████| 50/50 [00:00<00:00, 54.99it/s] \n",
      "[I 2024-05-31 12:49:17,644] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 50  (76.0): 100%|██████████| 50/50 [00:00<00:00, 56.18it/s]\n",
      "[I 2024-05-31 12:49:18,794] Trial 40 finished with value: 76.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:00<00:00, 54.47it/s] \n",
      "[I 2024-05-31 12:49:20,011] Trial 41 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 50  (76.0): 100%|██████████| 50/50 [00:02<00:00, 24.66it/s]\n",
      "[I 2024-05-31 12:49:22,260] Trial 42 finished with value: 76.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 50  (78.0): 100%|██████████| 50/50 [00:01<00:00, 42.09it/s]\n",
      "[I 2024-05-31 12:49:23,680] Trial 43 finished with value: 78.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [00:00<00:00, 54.37it/s]\n",
      "[I 2024-05-31 12:49:24,923] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:02<00:00, 18.87it/s]\n",
      "[I 2024-05-31 12:49:27,798] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40 / 50  (80.0): 100%|██████████| 50/50 [00:00<00:00, 55.30it/s]\n",
      "[I 2024-05-31 12:49:28,907] Trial 46 finished with value: 80.0 and parameters: {'12551179920_predictor_instruction': 3, '12551179920_predictor_demos': 3}. Best is trial 35 with value: 82.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 50  (54.0): 100%|██████████| 50/50 [00:02<00:00, 24.37it/s]\n",
      "[I 2024-05-31 12:49:31,177] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [00:06<00:00,  8.08it/s]\n",
      "[I 2024-05-31 12:49:37,608] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Starting trial #49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 50  (46.0): 100%|██████████| 50/50 [00:01<00:00, 28.45it/s]\n",
      "[I 2024-05-31 12:49:39,694] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial pruned.\n",
      "Returning predict = Predict(StringSignature(output -> sentiment\n",
      "    instructions='Generate an informative response based on the given input about Samsung products, including features, specifications, user experiences, and comparisons with other brands. Provide detailed insights and analysis to assist potential customers in making informed purchasing decisions.'\n",
      "    output = Field(annotation=str required=True json_schema_extra={'desc': 'Output of the LLM talking about the product', '__dspy_field_type': 'input', 'prefix': 'Output:'})\n",
      "    sentiment = Field(annotation=Sentiment required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'In-depth Analysis:', 'desc': '${sentiment}'})\n",
      ")) from continue_program\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPRO\n",
    "\n",
    "prompt_model = dspy.OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=2048,\n",
    ")\n",
    "optimizer = MIPRO(prompt_model=prompt_model, task_model=llm, metric=sentiment_matches, num_candidates=10)\n",
    "kwargs = dict(num_threads=64, display_progress=True, display_table=0)\n",
    "\n",
    "\n",
    "langwatch.dspy.init(experiment=\"product_sentiment_polarity_openai_experiment\", optimizer=optimizer)\n",
    "\n",
    "optimized_evaluator = optimizer.compile(ProductSentimentPolarity(), trainset=trainset_50, max_bootstrapped_demos=8, num_trials=50, max_labeled_demos=8, eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 81  (72.8): 100%|██████████| 81/81 [00:11<00:00,  6.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.84"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate_dev = Evaluate(devset=devset, metric=sentiment_matches, num_threads=4, display_progress=True, display_table=0)\n",
    "\n",
    "dev_score = evaluate_dev(optimized_evaluator)\n",
    "dev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy MIPRO** - 72.84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conclusions\n",
    "\n",
    "### Results and Comparison\n",
    "The baseline accuracy of gpt-3.5-turbo is 43.8%.\n",
    "\n",
    "**DSPy Optimizers Leaderboard**\n",
    "1. MIPRO - 72.84%\n",
    "2. BootstrapFewShotWithOptuna - 71.6%\n",
    "3. BootstrapFewShot - 60.49%\n",
    "4. BootstrapFewShotWithRandomSearch - 59.26%\n",
    "5. KNNFewShot - 50.62%\n",
    "6. COPRO - 43.21%\n",
    "\n",
    "Most of the optimizers have shown moderate to significant improvement compared to the baseline model accuracy.\n",
    "\n",
    "### Future Improvements for the Notebook\n",
    "Add confusion matrices for each evaluator to see which categories are most often mislabeled.\n",
    "\n",
    "### Notes and Discussion\n",
    "General notes about the experiment:\n",
    "1. For MIPRO and COPRO optimizations, the given training dataset was too small. Better results could potentially be achieved with more data and a bigger budget available.\n",
    "2. The quality of the whole dataset is not verified as it was artificially created by an LLM. Although it fully suffices for the primary goal of this experiment - to verify if DSPy optimizers can actually improve the results. Experiments with human-LLM interaction datasets would be interesting to explore in future trials. Additionally, experiments with human-made answers should be explored in the next experiments.\n",
    "3. For simplicity, the task was defined as a basic classification, and the requirement for \"reasoning\" or \"positive_points\" and \"negative_points\" was lifted. It is worth exploring further how priming would affect the final decision of an LLM.\n",
    "4. As the documentation of the DSPy library does not cover all the details, not all of the optimizers were used with optimal input parameters. The selection of most input parameters was based on the examples given in the [DSPy Cheatsheet](https://dspy-docs.vercel.app/docs/cheatsheet). We believe that certain optimizers could show better accuracy if the input parameters were chosen more thoroughly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

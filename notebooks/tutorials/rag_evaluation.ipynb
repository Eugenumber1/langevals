{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the tracing\n",
    "To start tracing your RAG you can add LangWatch wrappers to your functions. This is an example of tracing of your application in production. You can read more about it here - [RAGs Context Tracking](https://docs.langwatch.ai/rags/rags-context-tracking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenyabudnyk/DevProjects/langwatch-saas/langevals/notebooks/.venv/lib/python3.12/site-packages/langwatch/tracer.py:260: UserWarning: LANGWATCH_API_KEY is not set, LLMs traces will not be sent, go to https://langwatch.ai to set it up\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import langwatch \n",
    "from langwatch import openai\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "with openai.OpenAITracer(client):\n",
    "  with langwatch.capture_rag(\n",
    "      input=\"What is the capital of France?\",\n",
    "      contexts=[\n",
    "          {\n",
    "              \"document_id\": \"doc-1\",\n",
    "              \"chunk_id\": \"0\",\n",
    "              \"content\": \"France is a country in Europe.\",\n",
    "          },\n",
    "          {\n",
    "              \"document_id\": \"doc-2\",\n",
    "              \"chunk_id\": \"0\",\n",
    "              \"content\": \"Paris is the capital of France.\",\n",
    "          },\n",
    "      ],\n",
    "  ):\n",
    "      response = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "              {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "          ],\n",
    "      )\n",
    "\n",
    "\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "If you want to evaluate a few simple examples that you created manually or copy pasted from the dataset - you can do it in the following way.\n",
    "Import the evaluators of your choice from `langevals` module. In case of RAG evaluations you need only `Entry` and `Evaluator` objects. Then, you can fill in the arguments of `Entry` instances with `input` - question to the RAG app, `output` - the generated response and `contexts` - retrieved contexts that were used for generation. For evaluation to run successfully you need at least two input parameters.\n",
    "Finally, you can run each evaluator and get the evaluation `Result` objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"langevals[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status='processed' score=1.0 passed=None details=None cost=Money(currency='USD', amount=0.002036)\n",
      "status='processed' score=0.3333333333333333 passed=None details=None cost=Money(currency='USD', amount=0.00033600000000000004)\n",
      "status='processed' score=1.0 passed=None details=None cost=Money(currency='USD', amount=0.0038910000000000004)\n"
     ]
    }
   ],
   "source": [
    "from langevals_ragas.context_relevancy import RagasContextRelevancyEntry, RagasContextRelevancyEvaluator\n",
    "from langevals_ragas.faithfulness import RagasFaithfulnessEntry, RagasFaithfulnessEvaluator\n",
    "from langevals_ragas.answer_relevancy import RagasAnswerRelevancyEntry, RagasAnswerRelevancyEvaluator\n",
    "\n",
    "\n",
    "entry1 = RagasAnswerRelevancyEntry(input=\"What is the capital of France?\", output=\"Paris is the capital of France\")\n",
    "\n",
    "entry2 = RagasContextRelevancyEntry(output=\"Paris is the capital of France\", contexts=[\n",
    "    \"Water can evaporate or turn into ice\",\n",
    "    \"Dogs and Cats can be friends\",\n",
    "    \"The sun is shining today\"\n",
    "])\n",
    "\n",
    "entry3 = RagasFaithfulnessEntry(output=\"Paris is the capital of France\", contexts=[\n",
    "    \"France is a country in Europe\",\n",
    "    \"Lyon, Paris and Bordeaux are cities in France\",\n",
    "    \"Paris is the capital of France\"\n",
    "])\n",
    "\n",
    "result1 = RagasAnswerRelevancyEvaluator().evaluate(entry=entry1)\n",
    "result2 = RagasContextRelevancyEvaluator().evaluate(entry=entry2)\n",
    "result3 = RagasFaithfulnessEvaluator().evaluate(entry=entry3)\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

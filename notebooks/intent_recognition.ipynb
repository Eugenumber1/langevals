{
"cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with Intent Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv pandas openai ipywidgets litellm tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()\n",
    "import os\n",
    "import pandas as pd\n",
    "from tenacity import retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./notebooks/data && \\\n",
    "    curl https://amazon-massive-nlu-dataset.s3.amazonaws.com/amazon-massive-dataset-1.0.tar.gz --output amazon-massive-dataset-1.0.tar.gz && \\\n",
    "    tar -xzvf amazon-massive-dataset-1.0.tar.gz && \\\n",
    "    ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./notebooks/data/1.0/data/en-US.jsonl\"\n",
    "\n",
    "# Read the JSONL file\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the intents from the fraction of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = df[df[\"partition\"].str.contains(\"test\")]\n",
    "print(len(df_sampled))\n",
    "df_sampled = df_sampled.sample(frac=0.3, random_state=5)\n",
    "print(len(df_sampled))\n",
    "intents = set(df_sampled['intent'])\n",
    "# print(len(intents))\n",
    "test_set = df_sampled['utt']\n",
    "print(len(intents))\n",
    "print(len(test_set))\n",
    "print(test_set)\n",
    "\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import completion\n",
    "import json\n",
    "\n",
    "from tenacity import stop_after_attempt, wait_exponential\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "# model = \"groq/mixtral-8x7b-32768\"\n",
    "# model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "litellm.set_verbose=False\n",
    "\n",
    "# to call chatgpt\n",
    "def call_gpt(entry: str) -> str:\n",
    "    try:\n",
    "        response = completion(\n",
    "            model=model,\n",
    "            temperature=0.0,\n",
    "            tools=[\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"identify_intent\",\n",
    "                        \"description\": \"Identify the intent of the message using the best match from the provided enum list\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"intent\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The intent of the user message, what is the message about.\",\n",
    "                                    \"enum\": list(intents),\n",
    "                                },\n",
    "                            },\n",
    "                            \"required\": [\"intent\"],\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"You are an intent classification system. Your goal is to identify the intent of the message.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"{entry}\"},\n",
    "            ],\n",
    "        )\n",
    "        response = response.choices[0].message.tool_calls\n",
    "        if response:\n",
    "            try:\n",
    "                intent = json.loads(response[0].function.arguments)[\"intent\"]\n",
    "            except Exception as e:\n",
    "                return \"No intent argument found\"\n",
    "        else:\n",
    "            return \"No tool call\"\n",
    "        return intent\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "# single message test\n",
    "call_gpt(\"brighten up the lighting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "def call_gpt_with_index(index_entry):\n",
    "    index, entry = index_entry\n",
    "    result = call_gpt(entry)\n",
    "    return index, result\n",
    "\n",
    "if \"claude\" in model:\n",
    "    from tqdm import tqdm\n",
    "    generated_intents = list()\n",
    "    for entry in tqdm(test_set, 'processing'):\n",
    "        time.sleep(0.1)\n",
    "        intent = call_gpt(entry)\n",
    "        generated_intents.append(intent)\n",
    "else:\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        futures = [executor.submit(call_gpt_with_index, (index, entry)) for index, entry in enumerate(test_set)]\n",
    "        results_with_index = [future.result() for future in tqdm(as_completed(futures), total=len(test_set), desc='Processing')]\n",
    "        results_with_index.sort(key=lambda x: x[0])\n",
    "        generated_intents = [result for _, result in results_with_index]\n",
    "\n",
    "print(len(generated_intents), generated_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled['generated_intent'] = generated_intents\n",
    "df_sampled.to_csv(f\"./notebooks/data/1.0/data/en-US-labeled-{model}.csv\")\n",
    "df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i, row in df_sampled.iterrows():\n",
    "    if row['intent'] == row['generated_intent']:\n",
    "        counter += 1\n",
    "    else:\n",
    "        print(\n",
    "            f\"This is the predicted one - {row['generated_intent']} and it's the actual intent {row['intent']} at index - {i}\"\n",
    "        )\n",
    "\n",
    "print(counter)\n",
    "print(f\"Ratio - {counter} out of {len(df_sampled)} are correct, accuracy is = {(counter / len(df_sampled)) * 100} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
